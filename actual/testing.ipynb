{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Testing a few ideas:\n",
    "1. Should we remove essential nodes from the graph and then do analysis or do our analysis and remove essential nodes from consideration?\n",
    "2. Looking for 'intermediate nodes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in graph \n",
    "G = nx.read_weighted_edgelist(\"yeast.txt\",comments=\"#\",nodetype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting edges that don't meet threshold score\n",
    "threshold_score = 700\n",
    "for edge in G.edges: \n",
    "  weight = list(G.get_edge_data(edge[0],edge[1]).values())\n",
    "  if(weight[0] <= threshold_score):\n",
    "    G.remove_edge(edge[0],edge[1])\n",
    "\n",
    "G = nx.relabel_nodes(G, lambda x: x[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing essential nodes\n",
    "df = pd.read_csv(\"essential_proteins.csv\", header=None)\n",
    "essential_proteins = df[1].values\n",
    "\n",
    "G_essential = G.copy()\n",
    "\n",
    "for protein in essential_proteins:\n",
    "  str = protein\n",
    "  if str in G_essential.nodes:\n",
    "    G_essential.remove_node(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion Point #1\n",
    "\n",
    "Closeness centrality is defined as average length of the shortest path between a node $i$ and all other nodes in the graph. Since there is a  correlation between essential nodes and their degree/betweenness centrality, many shortest paths will likely go through these essential nodes (this can be supported). Suppose node $i$ is not an essential node and has many connections to essential nodes, but node $j$ has relatively fewer. This means that removing essential nodes has a disproportionate effect on the closeness centrality of node $i$ compared to node $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = nx.algorithms.closeness_centrality(G).items()\n",
    "\n",
    "cc_essential = nx.algorithms.closeness_centrality(G_essential).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 YMR186W YEL021W\n",
      "1 YEL021W YMR186W\n",
      "2 YMR116C YLL013C\n",
      "3 YLL013C YMR116C\n",
      "4 YPR080W YPR080W\n",
      "5 YML063W YLR178C\n",
      "6 YBR010W YLL026W\n",
      "7 YLR441C YBR010W\n",
      "8 YLL039C YLL039C\n",
      "9 YGR192C YGR192C\n",
      "10 YJR066W YGR088W\n",
      "11 YKL009W YEL009C\n",
      "12 YFR031C-A YKR094C\n",
      "13 YIL018W YJR066W\n",
      "14 YKL081W YBR251W\n",
      "15 YKR094C YLR441C\n",
      "16 YBL099W YIL148W\n",
      "17 YDR101C YMR250W\n",
      "18 YJR113C YMR105C\n",
      "19 YEL009C YML063W\n"
     ]
    }
   ],
   "source": [
    "cc = sorted(list(cc), key = lambda x: x[1], reverse=True)\n",
    "cc_essential = sorted(list(cc_essential), key = lambda x: x[1], reverse=True)\n",
    "\n",
    "# Removing essential nodes from consideration from centrality measure\n",
    "cc = [(node, val) for node, val in cc if node not in essential_proteins]\n",
    "\n",
    "for i in range(0, 20):\n",
    "  print(i, cc[i][0], cc_essential[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding non-essential proteins with highest proportional connection to essential proteins\n",
    "d = {}\n",
    "\n",
    "for i in G.nodes:\n",
    "  if i not in essential_proteins and G.degree(i) != 0:\n",
    "    num_essential_neighbours = 0\n",
    "    for j in G[i]:\n",
    "      if j in essential_proteins:\n",
    "        num_essential_neighbours += 1\n",
    "    \n",
    "    d[i] = num_essential_neighbours/G.degree(i)\n",
    "\n",
    "d_list = sorted(list(d.items()), key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('YEL052W', 1.0), ('YJR127C', 1.0), ('YDR338C', 1.0), ('YOR113W', 1.0), ('YJL103C', 1.0), ('YGR109W-B', 1.0), ('YOL045W', 1.0), ('YKR061W', 1.0), ('YMR291W', 1.0), ('YKR051W', 1.0), ('YOR320C', 1.0), ('YKL051W', 1.0), ('YLR302C', 1.0), ('YIL055C', 1.0), ('YLR146W-A', 1.0), ('YBL009W', 1.0), ('YDR528W', 1.0), ('YBL025W', 1.0), ('YOR183W', 1.0), ('YDR524W-C', 1.0)]\n"
     ]
    }
   ],
   "source": [
    "print(d_list[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23232507778191047\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(nx.algorithms.closeness_centrality(G, u = 'YEL052W'))\n",
    "print(nx.algorithms.closeness_centrality(G_essential, u = 'YEL052W'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it becomes clear that a non-essential node such as \"YEL052W\", whose neighbours are all essential nodes, has a zero closeness centrality if we consider the graph with essential nodes removed, but otherwise is a fairly central node in the network.\n",
    "\n",
    "This problem is not unique to closeness centrality - the node \"YEL052W\" becomes isolated when all essential proteins are removed, so it has a zero centrality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion Point #2\n",
    "We will check if there are isolated nodes in the NAFLD network. If there are, we see how many and look for 'intermediate nodes' (that are obviously not NAFLD nodes) to link them.\n",
    "\n",
    "See:\n",
    "\n",
    "- https://cs.stackexchange.com/questions/93047/minimal-number-of-nodes-needed-to-connect-a-disconnected-graph\n",
    "- node-weighted steiner problem\n",
    "- connected vertex cover\n",
    "- steiner tree (using networkx) but with edge weights of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting list of all yeast homologs\n",
    "df = pd.read_csv(\"human_to_yeast.csv\")\n",
    "\n",
    "# Note: some homologs in this list may also be present in the essential nodes list, so they wont be included in the subgraph.\n",
    "homologs = list(set(list(df[\"homolog_systematic_name\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting subgraph induced by all yeast homologs\n",
    "NAFLD = G.subgraph(homologs).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YLL055W', 'YJR001W', 'YDR151C', 'YDR105C', 'YPR058W', 'YCR075C', 'YHR078W', 'YLL048C', 'YJL079C', 'YDR372C', 'YDL219W', 'YPL088W', 'YLL061W', 'YDR338C', 'YAL067C', 'YJR100C', 'YKL198C', 'YER140W', 'YBL057C', 'YCR028C', 'YLR001C', 'YGL159W', 'YOL119C', 'YBR210W', 'YLR004C', 'YDR221W', 'YOR093C', 'YOR280C', 'YBR046C', 'YML087C', 'YMR212C', 'YJR085C', 'YHR032W', 'YOR256C', 'YER159C', 'YBR233W', 'YDR371W', 'YDR236C', 'YCR028C-A', 'YMR222C', 'YPR131C', 'YBR104W', 'YEL016C', 'YCR026C', 'YKR013W', 'YJR126C', 'YGL096W', 'YGR065C', 'YML125C']\n"
     ]
    }
   ],
   "source": [
    "print(list(nx.isolates(NAFLD)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate graph where all edge weights are 1\n",
    "H = G.copy()\n",
    "for (u, v, d) in H.edges().data():\n",
    "  d['weight'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YLL055W', 'YJR001W', 'YDR151C', 'YDR105C', 'YPR058W', 'YCR075C', 'YHR078W', 'YLL048C', 'YJL079C', 'YDR372C', 'YDL219W', 'YPL088W', 'YLL061W', 'YDR338C', 'YAL067C', 'YJR100C', 'YKL198C', 'YER140W', 'YBL057C', 'YCR028C', 'YLR001C', 'YGL159W', 'YOL119C', 'YBR210W', 'YLR004C', 'YDR221W', 'YOR093C', 'YOR280C', 'YBR046C', 'YML087C', 'YMR212C', 'YJR085C', 'YOR256C', 'YER159C', 'YBR233W', 'YDR371W', 'YDR236C', 'YCR028C-A', 'YPR131C', 'YBR104W', 'YCR026C', 'YKR013W', 'YJR126C', 'YGL096W', 'YGR065C', 'YML125C']\n"
     ]
    }
   ],
   "source": [
    "GC = H.subgraph(max(nx.connected_components(H), key=len)).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YLL055W', 'YJR001W', 'YDR151C', 'YDR105C', 'YPR058W', 'YCR075C', 'YHR078W', 'YLL048C', 'YJL079C', 'YDR372C', 'YDL219W', 'YPL088W', 'YLL061W', 'YDR338C', 'YAL067C', 'YJR100C', 'YKL198C', 'YER140W', 'YBL057C', 'YCR028C', 'YLR001C', 'YGL159W', 'YOL119C', 'YBR210W', 'YLR004C', 'YDR221W', 'YOR093C', 'YOR280C', 'YBR046C', 'YML087C', 'YMR212C', 'YJR085C', 'YOR256C', 'YER159C', 'YBR233W', 'YDR371W', 'YDR236C', 'YCR028C-A', 'YPR131C', 'YBR104W', 'YCR026C', 'YKR013W', 'YJR126C', 'YGL096W', 'YGR065C', 'YML125C']\n",
      "Graph with 5091 nodes and 81418 edges\n"
     ]
    }
   ],
   "source": [
    "# Removing NAFLD nodes\n",
    "for node in homologs:\n",
    "  if node not in nx.isolates(NAFLD) and node in GC.nodes():\n",
    "    GC.remove_node(node)\n",
    "\n",
    "\n",
    "ST_GC = GC.subgraph(max(nx.connected_components(GC), key=len)).copy()\n",
    "\n",
    "isolated = []\n",
    "\n",
    "for node in list(nx.isolates(NAFLD)):\n",
    "  if node in ST_GC.nodes():\n",
    "    isolated.append(node)\n",
    "\n",
    "print(isolated)\n",
    "\n",
    "print(ST_GC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\amool\\Desktop\\Capstones\\math-bcmb3888\\actual\\testing.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/amool/Desktop/Capstones/math-bcmb3888/actual/testing.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ST \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mapproximation\u001b[39m.\u001b[39;49msteiner_tree(ST_GC, terminal_nodes\u001b[39m=\u001b[39;49misolated)\n",
      "File \u001b[1;32m<class 'networkx.utils.decorators.argmap'> compilation 17:4\u001b[0m, in \u001b[0;36margmap_steiner_tree_14\u001b[1;34m(G, terminal_nodes, weight)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpath\u001b[39;00m \u001b[39mimport\u001b[39;00m splitext\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcontextlib\u001b[39;00m \u001b[39mimport\u001b[39;00m contextmanager\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnetworkx\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnx\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnetworkx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m create_random_state, create_py_random_state\n",
      "File \u001b[1;32mc:\\Users\\amool\\anaconda3\\lib\\site-packages\\networkx\\algorithms\\approximation\\steinertree.py:92\u001b[0m, in \u001b[0;36msteiner_tree\u001b[1;34m(G, terminal_nodes, weight)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39m\"\"\"Return an approximation to the minimum Steiner tree of a graph.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[0;32m     53\u001b[0m \u001b[39mThe minimum Steiner tree of `G` w.r.t a set of `terminal_nodes`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39m   https://en.wikipedia.org/wiki/Steiner_tree_problem\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39m# H is the subgraph induced by terminal_nodes in the metric closure M of G.\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m M \u001b[39m=\u001b[39m metric_closure(G, weight\u001b[39m=\u001b[39;49mweight)\n\u001b[0;32m     93\u001b[0m H \u001b[39m=\u001b[39m M\u001b[39m.\u001b[39msubgraph(terminal_nodes)\n\u001b[0;32m     94\u001b[0m \u001b[39m# Use the 'distance' attribute of each edge provided by M.\u001b[39;00m\n",
      "File \u001b[1;32m<class 'networkx.utils.decorators.argmap'> compilation 21:4\u001b[0m, in \u001b[0;36margmap_metric_closure_18\u001b[1;34m(G, weight)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpath\u001b[39;00m \u001b[39mimport\u001b[39;00m splitext\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcontextlib\u001b[39;00m \u001b[39mimport\u001b[39;00m contextmanager\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnetworkx\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnx\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnetworkx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m create_random_state, create_py_random_state\n",
      "File \u001b[1;32mc:\\Users\\amool\\anaconda3\\lib\\site-packages\\networkx\\algorithms\\approximation\\steinertree.py:41\u001b[0m, in \u001b[0;36mmetric_closure\u001b[1;34m(G, weight)\u001b[0m\n\u001b[0;32m     38\u001b[0m     M\u001b[39m.\u001b[39madd_edge(u, v, distance\u001b[39m=\u001b[39mdistance[v], path\u001b[39m=\u001b[39mpath[v])\n\u001b[0;32m     40\u001b[0m \u001b[39m# first node done -- now process the rest\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[39mfor\u001b[39;00m u, (distance, path) \u001b[39min\u001b[39;00m all_paths_iter:\n\u001b[0;32m     42\u001b[0m     Gnodes\u001b[39m.\u001b[39mremove(u)\n\u001b[0;32m     43\u001b[0m     \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m Gnodes:\n",
      "File \u001b[1;32mc:\\Users\\amool\\anaconda3\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py:1004\u001b[0m, in \u001b[0;36mall_pairs_dijkstra\u001b[1;34m(G, cutoff, weight)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[39m\"\"\"Find shortest weighted paths and lengths between all nodes.\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \n\u001b[0;32m    943\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[39mThe yielded dicts only have keys for reachable nodes.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m G:\n\u001b[1;32m-> 1004\u001b[0m     dist, path \u001b[39m=\u001b[39m single_source_dijkstra(G, n, cutoff\u001b[39m=\u001b[39;49mcutoff, weight\u001b[39m=\u001b[39;49mweight)\n\u001b[0;32m   1005\u001b[0m     \u001b[39myield\u001b[39;00m (n, (dist, path))\n",
      "File \u001b[1;32mc:\\Users\\amool\\anaconda3\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py:472\u001b[0m, in \u001b[0;36msingle_source_dijkstra\u001b[1;34m(G, source, target, cutoff, weight)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msingle_source_dijkstra\u001b[39m(G, source, target\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cutoff\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, weight\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    377\u001b[0m     \u001b[39m\"\"\"Find shortest weighted paths and lengths from a source node.\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \n\u001b[0;32m    379\u001b[0m \u001b[39m    Compute the shortest path length between source and all other\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[39m    single_source_bellman_ford\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m     \u001b[39mreturn\u001b[39;00m multi_source_dijkstra(\n\u001b[0;32m    473\u001b[0m         G, {source}, cutoff\u001b[39m=\u001b[39;49mcutoff, target\u001b[39m=\u001b[39;49mtarget, weight\u001b[39m=\u001b[39;49mweight\n\u001b[0;32m    474\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\amool\\anaconda3\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py:739\u001b[0m, in \u001b[0;36mmulti_source_dijkstra\u001b[1;34m(G, sources, target, cutoff, weight)\u001b[0m\n\u001b[0;32m    737\u001b[0m weight \u001b[39m=\u001b[39m _weight_function(G, weight)\n\u001b[0;32m    738\u001b[0m paths \u001b[39m=\u001b[39m {source: [source] \u001b[39mfor\u001b[39;00m source \u001b[39min\u001b[39;00m sources}  \u001b[39m# dictionary of paths\u001b[39;00m\n\u001b[1;32m--> 739\u001b[0m dist \u001b[39m=\u001b[39m _dijkstra_multisource(\n\u001b[0;32m    740\u001b[0m     G, sources, weight, paths\u001b[39m=\u001b[39;49mpaths, cutoff\u001b[39m=\u001b[39;49mcutoff, target\u001b[39m=\u001b[39;49mtarget\n\u001b[0;32m    741\u001b[0m )\n\u001b[0;32m    742\u001b[0m \u001b[39mif\u001b[39;00m target \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    743\u001b[0m     \u001b[39mreturn\u001b[39;00m (dist, paths)\n",
      "File \u001b[1;32mc:\\Users\\amool\\anaconda3\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py:830\u001b[0m, in \u001b[0;36m_dijkstra_multisource\u001b[1;34m(G, sources, weight, pred, paths, cutoff, target)\u001b[0m\n\u001b[0;32m    828\u001b[0m     push(fringe, (\u001b[39m0\u001b[39m, \u001b[39mnext\u001b[39m(c), source))\n\u001b[0;32m    829\u001b[0m \u001b[39mwhile\u001b[39;00m fringe:\n\u001b[1;32m--> 830\u001b[0m     (d, _, v) \u001b[39m=\u001b[39m pop(fringe)\n\u001b[0;32m    831\u001b[0m     \u001b[39mif\u001b[39;00m v \u001b[39min\u001b[39;00m dist:\n\u001b[0;32m    832\u001b[0m         \u001b[39mcontinue\u001b[39;00m  \u001b[39m# already searched this node.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ST = nx.approximation.steiner_tree(ST_GC, terminal_nodes=isolated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "604b94c5f01275e050c2c00b5ea4e6efa3f121665dac1e4e1c804cbe8201972f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
