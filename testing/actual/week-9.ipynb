{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial notes from discussion with Georg\n",
    "- Georg likes PCA idea\n",
    "- Consider how we are no longer modelling protein complexes because we are removing nodes which may be involved. This may influence our choice of community finding algorithms (i.e. k-clique percolation will allow overlaps which better models what occurs in protein complexes, but is this even necessary? What is the biological connection between communities in our graph and the actual PPI network?)\n",
    "- Consider the connectedness of the resulting network after removing non-NAFLD nodes (is it fully-connected? How many isolated nodes are there?)\n",
    "- Graph centrality measures against degree. Consider their correlation and the intuitive meaning behind the graph. For example, in a betweenness vs degree graph, a low degree but high betweenness node may be a bottleneck. Nodes which buck the trend will be interesting to consider.\n",
    "- Use community finding to find clusters, then find bottlenecks between them (can even find functional stuff) by inducing a graph. \n",
    "- Consider taking one degree of separation for yeast homolog network so that we have the possibility of finding significant proteins which do not appear in literature. \n",
    "\n",
    "# Extra notes that I think of while writing code\n",
    "- Handling essential nodes: do we want to include them or exclude them???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in graph \n",
    "G = nx.read_weighted_edgelist(\"yeast.txt\",comments=\"#\",nodetype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting edges that don't meet threshold score\n",
    "threshold_score = 700\n",
    "for edge in G.edges: \n",
    "  weight = list(G.get_edge_data(edge[0],edge[1]).values())\n",
    "  if(weight[0] <= threshold_score):\n",
    "    G.remove_edge(edge[0],edge[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing essential nodes\n",
    "\n",
    "df = pd.read_csv(\"essential_proteins.csv\", header=None)\n",
    "essential_proteins = df[1].values\n",
    "\n",
    "for protein in essential_proteins:\n",
    "  str = \"4932.\" + protein\n",
    "  if str in G.nodes:\n",
    "    G.remove_node(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting list of all yeast homologs\n",
    "df = pd.read_csv(\"human_to_yeast.csv\")\n",
    "\n",
    "# Note: some homologs in this list may also be present in the essential nodes list, so they wont be included in the subgraph.\n",
    "homologs = list(set(list(df[\"homolog_systematic_name\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabeling nodes to get rid of \".4932\" tag\n",
    "H = nx.relabel_nodes(G, lambda x: x[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting subgraph induced by all yeast homologs\n",
    "H0 = H.subgraph(homologs).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting subgraph induced by all nodes with one degree of separation away from a yeast homolog\n",
    "l = []\n",
    "\n",
    "for node in H0.nodes:\n",
    "  l.extend(H[node].keys())\n",
    "  \n",
    "\n",
    "l = list(set(l))\n",
    "H1 = H.subgraph(l).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 5098 nodes and 53343 edges\n",
      "Size of giant component of H: 4639\n",
      "Number of isolated nodes of H: 428\n",
      "Graph with 3264 nodes and 46662 edges\n",
      "Size of giant component of H1: 3252\n",
      "Number of isolated nodes of H1: 8\n",
      "Graph with 602 nodes and 1968 edges\n",
      "Size of giant component of H0: 527\n",
      "Number of isolated nodes of H0: 58\n"
     ]
    }
   ],
   "source": [
    "print(H) # Removing essential nodes only \n",
    "print(f\"Size of giant component of H: {len(max(nx.connected_components(H), key=len))}\")\n",
    "print(f\"Number of isolated nodes of H: {len(list(nx.isolates(H)))}\")\n",
    "\n",
    "print(H1) # Removing essential nodes + all nodes not adjacent to a yeast homolog\n",
    "print(f\"Size of giant component of H1: {len(max(nx.connected_components(H1), key=len))}\")\n",
    "print(f\"Number of isolated nodes of H1: {len(list(nx.isolates(H1)))}\")\n",
    "\n",
    "print(H0) # Removing essential nodes + all nodes nodes which arent yeast homologs\n",
    "print(f\"Size of giant component of H0: {len(max(nx.connected_components(H0), key=len))}\")\n",
    "print(f\"Number of isolated nodes of H0: {len(list(nx.isolates(H0)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the giant component of networks H0 and H1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC0 = H.subgraph(max(nx.connected_components(H0), key=len)).copy()\n",
    "GC1 = H.subgraph(max(nx.connected_components(H1), key=len)).copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "604b94c5f01275e050c2c00b5ea4e6efa3f121665dac1e4e1c804cbe8201972f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
